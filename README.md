# Algorithm Samples

A collection of algorithms.

## Types of Algorithms

1. Sorting Algorithms (Bubble Sort, Quick Sort, Merge Sort, etc.): These are used to rearrange a given array or list elements according to a comparison operator on the elements.
2. Searching Algorithms (Binary Search, Linear Search, Depth-First Search, etc.): These are used to find a particular item in a data structure.
3. Graph Algorithms (Dijkstra's Algorithm, Bellman-Ford Algorithm, etc.): These are used to solve problems involving graphs, such as finding the shortest path between two nodes, finding the minimum spanning tree, etc.
4. String Search Algorithms (Knuth–Morris–Pratt Algorithm, Rabin-Karp Algorithm, etc.): These are used to find a pattern in a text.
5. Machine Learning Algorithms (Support Vector Machines, Decision Trees, Neural Networks, etc.): These are used to create models that learn from data and make predictions or decisions without being explicitly programmed to perform the task.
6. Clustering Algorithms (K-Means Clustering, Hierarchical Clustering, DBSCAN, etc.): These are used in unsupervised machine learning to group similar items together.
7. Optimization Algorithms (Gradient Descent, Genetic Algorithm, Particle Swarm Optimization, etc.): These are used to find the best solution (optimum) for a problem.
8. Computer Graphics Algorithms (Bresenham's line algorithm, Ray Tracing, Texture Mapping, etc.): These are used to generate and manipulate graphical content.
9. Procedural Generation Algorithms (Perlin Noise, Diamond-Square Algorithm, Voronoi Diagrams, etc.): These are used to automatically create content in games and simulations.
10. Quantum Computing Algorithms (Shor's Algorithm, Grover's Algorithm, etc.): These are used in the field of quantum computing.
11. Compression Algorithms (Huffman Coding, Run-Length Encoding, etc.): These are used to reduce the size of data without losing information.
12. Cryptographic Algorithms (RSA, AES, DES, etc.): These are used to secure data by converting it into a form that can only be read by someone who has the decryption key.
13. Image Processing Algorithms (Canny Edge Detection, Histogram Equalization, etc.): These are used to manipulate and analyze images.
14. Computer Vision Algorithms (Hough Transform, SIFT, SURF, etc.): These are used to gain high-level understanding from digital images or videos.
15. Natural Language Processing Algorithms (Bag of Words, TF-IDF, Word2Vec, etc.): These are used to process human language.
16. Bioinformatics Algorithms (Needleman-Wunsch Algorithm, Smith-Waterman Algorithm, etc.): These are used to solve problems related to biological data.
17. Geospatial Algorithms (Haversine Formula, Vincenty's formulae, etc.): These are used to solve problems related to the earth's surface.
18. Numerical Algorithms (Newton's Method, Gaussian Elimination, etc.): These are used to solve numerical problems.
19. Network Algorithms (PageRank, Link Analysis, etc.): These are used to analyze and understand networks.
20. Data Mining Algorithms (Apriori, Eclat, FP-Growth, etc.): These are used to extract patterns from large datasets.
21. Recommender System Algorithms (Collaborative Filtering, Content-Based Filtering, etc.): These are used to predict the "rating" or "preference" that a user would give to an item.
22. Game Theory Algorithms (Minimax, Alpha-Beta Pruning, etc.): These are used to determine the optimal strategy in games.
23. Reinforcement Learning Algorithms (Q-Learning, SARSA, DDPG, etc.): These are used to train software agents to take actions in an environment to maximize some notion of cumulative reward.
24. Genetic Algorithms: These are used to find approximate solutions to optimization and search problems.
25. Swarm Intelligence Algorithms (Ant Colony Optimization, Particle Swarm Optimization, etc.): These are used to solve optimization problems based on the collective behavior of decentralized, self-organized systems.
26. Multi-Objective Optimization Algorithms (NSGA-II, SPEA2, MOEA/D, etc.): These are used to solve optimization problems that involve more than one objective function to be optimized simultaneously.
27. Metaheuristic Algorithms (Simulated Annealing, Tabu Search, Harmony Search, etc.): These are high-level problem-independent algorithmic frameworks that provide a set of guidelines or strategies to develop heuristic optimization algorithms.
28. Evolutionary Algorithms (Genetic Algorithm, Differential Evolution, Evolution Strategies, etc.): These are used to solve optimization problems based on the mechanisms of evolution, such as reproduction, mutation, recombination, and selection.
29. Estimation of Distribution Algorithms (Univariate Marginal Distribution Algorithm, Bivariate Marginal Distribution Algorithm, etc.): These are used to solve optimization problems based on the use of probabilistic models to guide the search process.
30. Memetic Algorithms (Genetic Algorithm with Local Search, Differential Evolution with Local Search, etc.): These are used to solve optimization problems based on the combination of a population-based global search approach with a local search strategy.
31. Artificial Immune System Algorithms (Clonal Selection Algorithm, Negative Selection Algorithm, etc.): These are used to solve optimization problems based on the principles and processes of the immune systems of vertebrates.
32. Artificial Neural Network Algorithms (Backpropagation, Radial Basis Function Network, etc.): These are used to solve problems that require pattern recognition, prediction, classification, decision making, and control.
33. Deep Learning Algorithms (Convolutional Neural Network, Recurrent Neural Network, etc.): These are used to solve problems that require learning from large amounts of data.
34. Fuzzy Logic Algorithms (Fuzzy C-Means, Fuzzy ART, etc.): These are used to solve problems that involve uncertainty and imprecision.
35. Rough Set Algorithms (Variable Precision Rough Set, Dominance-Based Rough Set, etc.): These are used to solve problems that involve uncertainty, vagueness, and incompleteness of information.
36. Probabilistic Graphical Model Algorithms (Bayesian Network, Markov Random Field, etc.): These are used to solve problems that involve uncertainty and complexity.
37. Bayesian Inference Algorithms (Markov Chain Monte Carlo, Variational Bayesian Method, etc.): These are used to solve problems that involve updating probabilities based on evidence.
38. Monte Carlo Algorithms (Monte Carlo Integration, Monte Carlo Tree Search, etc.): These are used to solve problems that involve repeated random sampling to obtain numerical results.
39. Markov Chain Algorithms (Markov Chain Monte Carlo, Hidden Markov Model, etc.): These are used to solve problems that involve systems that undergo transitions from one state to another on a state space.
40. Time Series Analysis Algorithms (ARIMA, GARCH, etc.): These are used to analyze time series data.
41. Dimensionality Reduction Algorithms (Principal Component Analysis, Linear Discriminant Analysis, etc.): These are used to reduce the number of random variables to consider.
42. Feature Selection Algorithms (Recursive Feature Elimination, Sequential Feature Selection, etc.): These are used to select a subset of relevant features for use in model construction.
43. Feature Extraction Algorithms (Principal Component Analysis, Independent Component Analysis, etc.): These are used to construct combinations of variables to get around these issues while still describing the data with sufficient accuracy.
44. Instance Selection Algorithms (Condensed Nearest Neighbor, Edited Nearest Neighbor, etc.): These are used to select a subset of instances to speed up learning and generalization.
45. Prototype Generation Algorithms (LVQ, SOM, etc.): These are used to generate a set of representative instances that can summarize the original data.
46. Discretization Algorithms (Equal Width, Equal Frequency, etc.): These are used to transform numeric data by creating a finite partition of the value range.
47. Binarization Algorithms (Unimodal, Bi-Modal, etc.): These are used to transform numeric data into binary form.
48. Missing Values Imputation Algorithms (Mean Imputation, K-Nearest Neighbors, etc.): These are used to estimate missing values in the data.
49. Outlier Detection Algorithms (Z-Score, IQR, etc.): These are used to detect outliers in the data.
50. Anomaly Detection Algorithms (One-Class SVM, Isolation Forest, etc.): These are used to detect anomalies in the data.
51. Change Detection Algorithms (CUSUM, Page-Hinkley, etc.): These are used to detect changes in the data.
52. Concept Drift Detection Algorithms (DWM, ADWIN, etc.): These are used to detect changes in the underlying concepts in the data.
53. Class Imbalance Learning Algorithms (SMOTE, ADASYN, etc.): These are used to deal with imbalanced data.
54. Multi-Label Learning Algorithms (Binary Relevance, Classifier Chains, etc.): These are used to deal with multi-label data.
55. Multi-Instance Learning Algorithms (MILBoost, MI-SVM, etc.): These are used to deal with multi-instance data.
56. Multi-View Learning Algorithms (Co-Training, Multi-View SVM, etc.): These are used to deal with multi-view data.
57. Structured Output Learning Algorithms (CRF, Structured SVM, etc.): These are used to deal with structured output data.
58. Semi-Supervised Learning Algorithms (Self-Training, Co-Training, etc.): These are used to deal with partially labeled data.
59. Active Learning Algorithms (Uncertainty Sampling, Query-By-Committee, etc.): These are used to deal with situations where unlabeled data is abundant but labeling data is expensive.
60. Transfer Learning Algorithms (Domain-Adaptive SVM, Transfer AdaBoost, etc.): These are used to deal with situations where the distribution of the test data is different from the distribution of the training data.
61. Multi-Task Learning Algorithms (Multi-Task Lasso, Multi-Task Elastic Net, etc.): These are used to deal with situations where multiple related tasks are learned together.
62. Online Learning Algorithms (Perceptron, Online Passive-Aggressive, etc.): These are used to deal with situations where the data comes in sequential order and the learner has to update the model incrementally.
63. Ensemble Learning Algorithms (Bagging, Boosting, Stacking, etc.): These are used to combine multiple learners to improve the generalization ability of the model.
64. Cost-Sensitive Learning Algorithms (Cost-Sensitive Decision Trees, Cost-Sensitive SVM, etc.): These are used to deal with situations where the costs of different errors are different.
65. Class-Imbalance Learning Algorithms (SMOTE, ADASYN, etc.): These are used to deal with imbalanced data.
66. One-Class Learning Algorithms (One-Class SVM, One-Class Decision Trees, etc.): These are used to deal with situations where the training data contains only the positive class.
67. Rule Learning Algorithms (RIPPER, PART, etc.): These are used to extract a set of rules from the data.
68. Association Rule Learning Algorithms (Apriori, FP-Growth, etc.): These are used to extract a set of associations from the data.
69. Grammar Induction Algorithms (RPNI, LSTAR, etc.): These are used to extract a grammar from the data.
70. Formal Concept Analysis Algorithms (NextClosure, CloseByOne, etc.): These are used to extract a set of formal concepts from the data.
71. Biclustering Algorithms (Cheng & Church, Plaid Model, etc.): These are used to simultaneously cluster rows and columns of a matrix.
72. Collaborative Filtering Algorithms (User-Based, Item-Based, etc.): These are used to make automatic predictions about the interests of a user by collecting preferences from many users.
73. Content-Based Filtering Algorithms (TF-IDF, Cosine Similarity, etc.): These are used to recommend items by comparing the content of the items and a user profile.
74. Hybrid Recommender Systems (Weighted, Mixed, etc.): These are used to combine collaborative and content-based methods to overcome their individual limitations.
75. Multi-Criteria Recommender Systems (MOMA, MOEARec, etc.): These are used to recommend items by considering multiple criteria simultaneously.
76. Context-Aware Recommender Systems (Tensor Factorization, Contextual Bandit, etc.): These are used to recommend items by considering the context of the recommendation.
77. Group Recommender Systems (Aggregation Strategy, Group Modeling, etc.): These are used to recommend items to a group of users.
78. Social Recommender Systems (Trust-Based, Influence-Based, etc.): These are used to recommend items by considering the social relations among users.
79. Cross-Domain Recommender Systems (Linked-Based, Rating-Based, etc.):

## List of Algorithms

1. Bubble Sort
2. Quick Sort
3. Merge Sort
4. Insertion Sort
5. Selection Sort
6. Heap Sort
7. Radix Sort
8. Bucket Sort
9. Shell Sort
10. Counting Sort
11. Binary Search
12. Linear Search
13. Depth-First Search (DFS)
14. Breadth-First Search (BFS)
15. Dijkstra's Algorithm (Shortest Path)
16. A\* Search Algorithm
17. Floyd–Warshall Algorithm
18. Kruskal's Algorithm
19. Prim's Algorithm
20. Huffman Coding
21. Greedy Algorithm
22. Dynamic Programming
23. Backtracking Algorithm
24. Divide and Conquer Algorithm
25. Recursive Algorithm
26. Knapsack Problem
27. Travelling Salesman Problem
28. Tower of Hanoi
29. Binary Tree Traversal Algorithms (In-order, Pre-order, Post-order)
30. Graph Traversal Algorithms (DFS, BFS)
31. Bellman-Ford Algorithm (Shortest Path)
32. Johnson’s Algorithm (Shortest Path)
33. Knuth–Morris–Pratt Algorithm (String Search)
34. Rabin-Karp Algorithm (String Search)
35. Z Algorithm (String Search)
36. Naive Pattern Searching Algorithm
37. Boyer-Moore Algorithm (String Search)
38. Fisher-Yates Shuffle Algorithm
39. Monte Carlo Algorithm
40. Las Vegas Algorithm
41. Genetic Algorithm
42. Simulated Annealing
43. Ant Colony Optimization Algorithms
44. Particle Swarm Optimization Algorithms
45. Bresenham's line algorithm
46. Flood fill Algorithm
47. Union-Find Algorithm
48. Graham's Scan Algorithm
49. Gift Wrapping Algorithm
50. Ford-Fulkerson Algorithm (Maximum Flow)
51. Edmonds-Karp Algorithm (Maximum Flow)
52. Needleman-Wunsch Algorithm (Sequence Alignment)
53. Smith-Waterman Algorithm (Sequence Alignment)

## LICENSE

[MIT](LICENSE)
